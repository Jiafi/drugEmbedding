{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/yuke/PythonProject/DrugEmbedding/')\n",
    "data_dir = './data/tox21'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pylon5/ac5616p/yuke/anaconda3/envs/MolEnv2/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import deepchem as dc\n",
    "import json\n",
    "from tqdm import tnrange\n",
    "\n",
    "import decode\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.feat.base_classes import Featurizer\n",
    "class ATCDrugEmbedding(Featurizer):\n",
    "    def __init__(self, configs, model):\n",
    "        self.configs = configs\n",
    "        self.model = model\n",
    "\n",
    "    def _featurize(self, mol):\n",
    "        from rdkit import Chem\n",
    "        smi_can = Chem.MolToSmiles(mol)\n",
    "        mean, _ = decode.smiles2mean(self.configs, smi_can, self.model)\n",
    "        return mean.squeeze().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(model_dir):\n",
    "    sklearn_model = RandomForestClassifier(\n",
    "    class_weight=\"balanced\", n_estimators=500)\n",
    "    return dc.models.SklearnModel(sklearn_model, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lorentz Drug Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_dir': './data/fda_drugs',\n",
       " 'data_file': 'smiles_set_clean.smi',\n",
       " 'fda_file': 'all_drugs.smi',\n",
       " 'vocab_file': 'char_set_clean.pkl',\n",
       " 'atc_sim_file': 'drugs_sp_all.csv',\n",
       " 'checkpoint_dir': './experiments/KDD_SEED',\n",
       " 'experiment_name': 'kdd_l64_s2',\n",
       " 'task': 'vae + atc',\n",
       " 'limit': 0,\n",
       " 'batch_size': 128,\n",
       " 'epochs': 100,\n",
       " 'max_sequence_length': 120,\n",
       " 'learning_rate': 0.0003,\n",
       " 'max_norm': 1000000000000.0,\n",
       " 'wd': 0.0,\n",
       " 'manifold_type': 'Lorentz',\n",
       " 'prior_type': 'Standard',\n",
       " 'num_centroids': 0,\n",
       " 'bidirectional': False,\n",
       " 'num_layers': 1,\n",
       " 'hidden_size': 512,\n",
       " 'latent_size': 64,\n",
       " 'word_dropout_rate': 0.2,\n",
       " 'anneal_function': 'logistic',\n",
       " 'k': 0.51,\n",
       " 'x0': 29.0,\n",
       " 'C': 1.0,\n",
       " 'num_workers': 4,\n",
       " 'logging_steps': 1,\n",
       " 'save_per_epochs': 5,\n",
       " 'new_training': False,\n",
       " 'new_annealing': False,\n",
       " 'checkpoint': 'checkpoint_epoch120.model',\n",
       " 'trained_epochs': 65,\n",
       " 'alpha': 0.0,\n",
       " 'beta': 0.015625,\n",
       " 'gamma': 0.0,\n",
       " 'delta': 11.0,\n",
       " 'nneg': 11,\n",
       " 'fda_prop': 0.2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dir = './experiments/KDD_SEED/kdd_l64_s2'\n",
    "checkpoint = 'checkpoint_epoch120.model'\n",
    "config_path = os.path.join(exp_dir, 'configs.json')\n",
    "checkpoint_path = os.path.join(exp_dir, checkpoint)\n",
    "\n",
    "with open(config_path, 'r') as fp:\n",
    "    configs = json.load(fp)\n",
    "fp.close()\n",
    "\n",
    "configs['checkpoint'] = checkpoint\n",
    "model = decode.load_model(configs)\n",
    "\n",
    "configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 5-Fold Random Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21_tasks_lst = []\n",
    "tox21_datasets_lst = []\n",
    "transformers_lst = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from ./data/tox21/tox21.csv.gz\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "TIMING: featurizing shard 0 took 26.038 s\n",
      "TIMING: dataset construction took 26.174 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.106 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.034 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.033 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.101 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.016 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.017 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "ATCFeaturizer = ATCDrugEmbedding(configs, model)\n",
    "tox21_tasks, tox21_datasets, transformers = dc.molnet.load_tox21(featurizer=ATCFeaturizer, \n",
    "                                                                 split='random', \n",
    "                                                                 data_dir=data_dir,\n",
    "                                                                 reload=False)\n",
    "tox21_tasks_lst.append(tox21_tasks)\n",
    "tox21_datasets_lst.append(tox21_datasets)\n",
    "transformers_lst.append(transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from ./data/tox21/tox21.csv.gz\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "TIMING: featurizing shard 0 took 26.048 s\n",
      "TIMING: dataset construction took 26.185 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.107 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.034 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.033 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.101 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.016 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.016 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "ATCFeaturizer = ATCDrugEmbedding(configs, model)\n",
    "tox21_tasks, tox21_datasets, transformers = dc.molnet.load_tox21(featurizer=ATCFeaturizer, \n",
    "                                                                 split='random', \n",
    "                                                                 data_dir=data_dir,\n",
    "                                                                 reload=False)\n",
    "tox21_tasks_lst.append(tox21_tasks)\n",
    "tox21_datasets_lst.append(tox21_datasets)\n",
    "transformers_lst.append(transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from ./data/tox21/tox21.csv.gz\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "TIMING: featurizing shard 0 took 26.076 s\n",
      "TIMING: dataset construction took 26.209 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.106 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.034 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.033 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.101 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.016 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.016 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "ATCFeaturizer = ATCDrugEmbedding(configs, model)\n",
    "tox21_tasks, tox21_datasets, transformers = dc.molnet.load_tox21(featurizer=ATCFeaturizer, \n",
    "                                                                 split='random', \n",
    "                                                                 data_dir=data_dir,\n",
    "                                                                 reload=False)\n",
    "tox21_tasks_lst.append(tox21_tasks)\n",
    "tox21_datasets_lst.append(tox21_datasets)\n",
    "transformers_lst.append(transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fold 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from ./data/tox21/tox21.csv.gz\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "TIMING: featurizing shard 0 took 26.121 s\n",
      "TIMING: dataset construction took 26.254 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.106 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.033 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.034 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.101 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.016 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.016 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "ATCFeaturizer = ATCDrugEmbedding(configs, model)\n",
    "tox21_tasks, tox21_datasets, transformers = dc.molnet.load_tox21(featurizer=ATCFeaturizer, \n",
    "                                                                 split='random', \n",
    "                                                                 data_dir=data_dir,\n",
    "                                                                 reload=False)\n",
    "tox21_tasks_lst.append(tox21_tasks)\n",
    "tox21_datasets_lst.append(tox21_datasets)\n",
    "transformers_lst.append(transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fold 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from ./data/tox21/tox21.csv.gz\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "Featurizing sample 1000\n",
      "Featurizing sample 2000\n",
      "Featurizing sample 3000\n",
      "Featurizing sample 4000\n",
      "Featurizing sample 5000\n",
      "Featurizing sample 6000\n",
      "Featurizing sample 7000\n",
      "TIMING: featurizing shard 0 took 25.875 s\n",
      "TIMING: dataset construction took 26.008 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.106 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.033 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.033 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.102 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.016 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.016 s\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "ATCFeaturizer = ATCDrugEmbedding(configs, model)\n",
    "tox21_tasks, tox21_datasets, transformers = dc.molnet.load_tox21(featurizer=ATCFeaturizer, \n",
    "                                                                 split='random', \n",
    "                                                                 data_dir=data_dir,\n",
    "                                                                 reload=False)\n",
    "tox21_tasks_lst.append(tox21_tasks)\n",
    "tox21_datasets_lst.append(tox21_datasets)\n",
    "transformers_lst.append(transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_lst = []\n",
    "valid_scores_lst = []\n",
    "test_scores_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2f4466614d49d6b81943fa8ce26ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to initialize singletask to multitask model\n",
      "Initializing directory for task NR-AR\n",
      "Initializing directory for task NR-AR-LBD\n",
      "Initializing directory for task NR-AhR\n",
      "Initializing directory for task NR-Aromatase\n",
      "Initializing directory for task NR-ER\n",
      "Initializing directory for task NR-ER-LBD\n",
      "Initializing directory for task NR-PPAR-gamma\n",
      "Initializing directory for task SR-ARE\n",
      "Initializing directory for task SR-ATAD5\n",
      "Initializing directory for task SR-HSE\n",
      "Initializing directory for task SR-MMP\n",
      "Initializing directory for task SR-p53\n",
      "About to fit model\n",
      "About to create task-specific datasets\n",
      "Splitting multitask dataset into singletask datasets\n",
      "TIMING: dataset construction took 0.023 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.004 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "Processing shard 0\n",
      "\tTask NR-AR\n",
      "\tTask NR-AR-LBD\n",
      "\tTask NR-AhR\n",
      "\tTask NR-Aromatase\n",
      "\tTask NR-ER\n",
      "\tTask NR-ER-LBD\n",
      "\tTask NR-PPAR-gamma\n",
      "\tTask SR-ARE\n",
      "\tTask SR-ATAD5\n",
      "\tTask SR-HSE\n",
      "\tTask SR-MMP\n",
      "\tTask SR-p53\n",
      "Dataset for task NR-AR has shape ((5813, 65), (5813, 1), (5813, 1), (5813,))\n",
      "Dataset for task NR-AR-LBD has shape ((5396, 65), (5396, 1), (5396, 1), (5396,))\n",
      "Dataset for task NR-AhR has shape ((5247, 65), (5247, 1), (5247, 1), (5247,))\n",
      "Dataset for task NR-Aromatase has shape ((4663, 65), (4663, 1), (4663, 1), (4663,))\n",
      "Dataset for task NR-ER has shape ((4958, 65), (4958, 1), (4958, 1), (4958,))\n",
      "Dataset for task NR-ER-LBD has shape ((5578, 65), (5578, 1), (5578, 1), (5578,))\n",
      "Dataset for task NR-PPAR-gamma has shape ((5164, 65), (5164, 1), (5164, 1), (5164,))\n",
      "Dataset for task SR-ARE has shape ((4658, 65), (4658, 1), (4658, 1), (4658,))\n",
      "Dataset for task SR-ATAD5 has shape ((5660, 65), (5660, 1), (5660, 1), (5660,))\n",
      "Dataset for task SR-HSE has shape ((5168, 65), (5168, 1), (5168, 1), (5168,))\n",
      "Dataset for task SR-MMP has shape ((4650, 65), (4650, 1), (4650, 1), (4650,))\n",
      "Dataset for task SR-p53 has shape ((5419, 65), (5419, 1), (5419, 1), (5419,))\n",
      "Fitting model for task NR-AR\n",
      "Fitting model for task NR-AR-LBD\n",
      "Fitting model for task NR-AhR\n",
      "Fitting model for task NR-Aromatase\n",
      "Fitting model for task NR-ER\n",
      "Fitting model for task NR-ER-LBD\n",
      "Fitting model for task NR-PPAR-gamma\n",
      "Fitting model for task SR-ARE\n",
      "Fitting model for task SR-ATAD5\n",
      "Fitting model for task SR-HSE\n",
      "Fitting model for task SR-MMP\n",
      "Fitting model for task SR-p53\n",
      "Evaluating model\n",
      "computed_metrics: [1.0, 1.0, 0.9999973178747554, 1.0, 1.0, 1.0, 1.0, 0.9999998312224894, 0.9999987411661333, 1.0, 1.0, 0.9999999999999999]\n",
      "computed_metrics: [0.7471610227118184, 0.8754729505476269, 0.8475543053602126, 0.8054554554554555, 0.7784477287152054, 0.7856879606879608, 0.7998946814112691, 0.770323859881031, 0.789568345323741, 0.7710491755435576, 0.825412304957535, 0.8321309973663117]\n",
      "computed_metrics: [0.8701543181184345, 0.8693682898773006, 0.8018099913136578, 0.874829931972789, 0.7112063492063492, 0.8449475620060639, 0.6693668068266139, 0.7631062329897828, 0.8475472085385879, 0.7645299145299146, 0.8768156633722672, 0.8163538419840086]\n",
      "Train scores\n",
      "{'mean-roc_auc_score': 0.9999996575219482}\n",
      "Validation scores\n",
      "{'mean-roc_auc_score': 0.8023465656634771}\n",
      "Test scores\n",
      "{'mean-roc_auc_score': 0.8091696758946476}\n",
      "About to initialize singletask to multitask model\n",
      "Initializing directory for task NR-AR\n",
      "Initializing directory for task NR-AR-LBD\n",
      "Initializing directory for task NR-AhR\n",
      "Initializing directory for task NR-Aromatase\n",
      "Initializing directory for task NR-ER\n",
      "Initializing directory for task NR-ER-LBD\n",
      "Initializing directory for task NR-PPAR-gamma\n",
      "Initializing directory for task SR-ARE\n",
      "Initializing directory for task SR-ATAD5\n",
      "Initializing directory for task SR-HSE\n",
      "Initializing directory for task SR-MMP\n",
      "Initializing directory for task SR-p53\n",
      "About to fit model\n",
      "About to create task-specific datasets\n",
      "Splitting multitask dataset into singletask datasets\n",
      "TIMING: dataset construction took 0.004 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "Processing shard 0\n",
      "\tTask NR-AR\n",
      "\tTask NR-AR-LBD\n",
      "\tTask NR-AhR\n",
      "\tTask NR-Aromatase\n",
      "\tTask NR-ER\n",
      "\tTask NR-ER-LBD\n",
      "\tTask NR-PPAR-gamma\n",
      "\tTask SR-ARE\n",
      "\tTask SR-ATAD5\n",
      "\tTask SR-HSE\n",
      "\tTask SR-MMP\n",
      "\tTask SR-p53\n",
      "Dataset for task NR-AR has shape ((5812, 65), (5812, 1), (5812, 1), (5812,))\n",
      "Dataset for task NR-AR-LBD has shape ((5397, 65), (5397, 1), (5397, 1), (5397,))\n",
      "Dataset for task NR-AhR has shape ((5243, 65), (5243, 1), (5243, 1), (5243,))\n",
      "Dataset for task NR-Aromatase has shape ((4655, 65), (4655, 1), (4655, 1), (4655,))\n",
      "Dataset for task NR-ER has shape ((4949, 65), (4949, 1), (4949, 1), (4949,))\n",
      "Dataset for task NR-ER-LBD has shape ((5542, 65), (5542, 1), (5542, 1), (5542,))\n",
      "Dataset for task NR-PPAR-gamma has shape ((5140, 65), (5140, 1), (5140, 1), (5140,))\n",
      "Dataset for task SR-ARE has shape ((4684, 65), (4684, 1), (4684, 1), (4684,))\n",
      "Dataset for task SR-ATAD5 has shape ((5648, 65), (5648, 1), (5648, 1), (5648,))\n",
      "Dataset for task SR-HSE has shape ((5184, 65), (5184, 1), (5184, 1), (5184,))\n",
      "Dataset for task SR-MMP has shape ((4661, 65), (4661, 1), (4661, 1), (4661,))\n",
      "Dataset for task SR-p53 has shape ((5419, 65), (5419, 1), (5419, 1), (5419,))\n",
      "Fitting model for task NR-AR\n",
      "Fitting model for task NR-AR-LBD\n",
      "Fitting model for task NR-AhR\n",
      "Fitting model for task NR-Aromatase\n",
      "Fitting model for task NR-ER\n",
      "Fitting model for task NR-ER-LBD\n",
      "Fitting model for task NR-PPAR-gamma\n",
      "Fitting model for task SR-ARE\n",
      "Fitting model for task SR-ATAD5\n",
      "Fitting model for task SR-HSE\n",
      "Fitting model for task SR-MMP\n",
      "Fitting model for task SR-p53\n",
      "Evaluating model\n",
      "computed_metrics: [1.0, 1.0, 0.9999998238313854, 1.0, 1.0, 1.0, 1.0, 0.9999998305371971, 0.9999601188369039, 1.0, 1.0, 1.0]\n",
      "computed_metrics: [0.7449928469241774, 0.8319206408345754, 0.8278862478777589, 0.8375953228266396, 0.7119567521729913, 0.7683466478696741, 0.8426841085271317, 0.7854135338345865, 0.812372634643377, 0.7478101232625229, 0.8764442740286298, 0.8223076923076924]\n",
      "computed_metrics: [0.8345163209792588, 0.8355007704160247, 0.8527017629975049, 0.7791898577612864, 0.7206557914967422, 0.7654926790660863, 0.7071468259480483, 0.6995597539931862, 0.7295028630921394, 0.6451936584386916, 0.7938154984600756, 0.7827521559805024]\n",
      "Train scores\n",
      "{'mean-roc_auc_score': 0.9999966477671238}\n",
      "Validation scores\n",
      "{'mean-roc_auc_score': 0.8008109020924797}\n",
      "Test scores\n",
      "{'mean-roc_auc_score': 0.7621689948857955}\n",
      "About to initialize singletask to multitask model\n",
      "Initializing directory for task NR-AR\n",
      "Initializing directory for task NR-AR-LBD\n",
      "Initializing directory for task NR-AhR\n",
      "Initializing directory for task NR-Aromatase\n",
      "Initializing directory for task NR-ER\n",
      "Initializing directory for task NR-ER-LBD\n",
      "Initializing directory for task NR-PPAR-gamma\n",
      "Initializing directory for task SR-ARE\n",
      "Initializing directory for task SR-ATAD5\n",
      "Initializing directory for task SR-HSE\n",
      "Initializing directory for task SR-MMP\n",
      "Initializing directory for task SR-p53\n",
      "About to fit model\n",
      "About to create task-specific datasets\n",
      "Splitting multitask dataset into singletask datasets\n",
      "TIMING: dataset construction took 0.004 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "Processing shard 0\n",
      "\tTask NR-AR\n",
      "\tTask NR-AR-LBD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTask NR-AhR\n",
      "\tTask NR-Aromatase\n",
      "\tTask NR-ER\n",
      "\tTask NR-ER-LBD\n",
      "\tTask NR-PPAR-gamma\n",
      "\tTask SR-ARE\n",
      "\tTask SR-ATAD5\n",
      "\tTask SR-HSE\n",
      "\tTask SR-MMP\n",
      "\tTask SR-p53\n",
      "Dataset for task NR-AR has shape ((5811, 65), (5811, 1), (5811, 1), (5811,))\n",
      "Dataset for task NR-AR-LBD has shape ((5397, 65), (5397, 1), (5397, 1), (5397,))\n",
      "Dataset for task NR-AhR has shape ((5248, 65), (5248, 1), (5248, 1), (5248,))\n",
      "Dataset for task NR-Aromatase has shape ((4670, 65), (4670, 1), (4670, 1), (4670,))\n",
      "Dataset for task NR-ER has shape ((4950, 65), (4950, 1), (4950, 1), (4950,))\n",
      "Dataset for task NR-ER-LBD has shape ((5573, 65), (5573, 1), (5573, 1), (5573,))\n",
      "Dataset for task NR-PPAR-gamma has shape ((5155, 65), (5155, 1), (5155, 1), (5155,))\n",
      "Dataset for task SR-ARE has shape ((4645, 65), (4645, 1), (4645, 1), (4645,))\n",
      "Dataset for task SR-ATAD5 has shape ((5660, 65), (5660, 1), (5660, 1), (5660,))\n",
      "Dataset for task SR-HSE has shape ((5169, 65), (5169, 1), (5169, 1), (5169,))\n",
      "Dataset for task SR-MMP has shape ((4647, 65), (4647, 1), (4647, 1), (4647,))\n",
      "Dataset for task SR-p53 has shape ((5412, 65), (5412, 1), (5412, 1), (5412,))\n",
      "Fitting model for task NR-AR\n",
      "Fitting model for task NR-AR-LBD\n",
      "Fitting model for task NR-AhR\n",
      "Fitting model for task NR-Aromatase\n",
      "Fitting model for task NR-ER\n",
      "Fitting model for task NR-ER-LBD\n",
      "Fitting model for task NR-PPAR-gamma\n",
      "Fitting model for task SR-ARE\n",
      "Fitting model for task SR-ATAD5\n",
      "Fitting model for task SR-HSE\n",
      "Fitting model for task SR-MMP\n",
      "Fitting model for task SR-p53\n",
      "Evaluating model\n",
      "computed_metrics: [1.0, 1.0, 0.999999826230324, 1.0, 1.0, 1.0, 1.0, 0.9999998271609034, 0.9999891772642895, 1.0, 1.0, 1.0]\n",
      "computed_metrics: [0.9132225254279336, 0.8891504946727549, 0.8438795605306799, 0.832730857706211, 0.7866054613935969, 0.8284141726866185, 0.7597419028340081, 0.7654858299595142, 0.8300021039343572, 0.8017451298701299, 0.8983615221987316, 0.7824994497835815]\n",
      "computed_metrics: [0.7523242658271435, 0.8226724430852872, 0.820139480990796, 0.8084187261402451, 0.671088647714176, 0.7552873672230653, 0.7582271762208068, 0.7292994213725921, 0.7787883094121548, 0.7232971014492753, 0.8428311915494853, 0.7644875764070811]\n",
      "Train scores\n",
      "{'mean-roc_auc_score': 0.999999069221293}\n",
      "Validation scores\n",
      "{'mean-roc_auc_score': 0.8276532509165099}\n",
      "Test scores\n",
      "{'mean-roc_auc_score': 0.7689051422826757}\n",
      "About to initialize singletask to multitask model\n",
      "Initializing directory for task NR-AR\n",
      "Initializing directory for task NR-AR-LBD\n",
      "Initializing directory for task NR-AhR\n",
      "Initializing directory for task NR-Aromatase\n",
      "Initializing directory for task NR-ER\n",
      "Initializing directory for task NR-ER-LBD\n",
      "Initializing directory for task NR-PPAR-gamma\n",
      "Initializing directory for task SR-ARE\n",
      "Initializing directory for task SR-ATAD5\n",
      "Initializing directory for task SR-HSE\n",
      "Initializing directory for task SR-MMP\n",
      "Initializing directory for task SR-p53\n",
      "About to fit model\n",
      "About to create task-specific datasets\n",
      "Splitting multitask dataset into singletask datasets\n",
      "TIMING: dataset construction took 0.004 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "Processing shard 0\n",
      "\tTask NR-AR\n",
      "\tTask NR-AR-LBD\n",
      "\tTask NR-AhR\n",
      "\tTask NR-Aromatase\n",
      "\tTask NR-ER\n",
      "\tTask NR-ER-LBD\n",
      "\tTask NR-PPAR-gamma\n",
      "\tTask SR-ARE\n",
      "\tTask SR-ATAD5\n",
      "\tTask SR-HSE\n",
      "\tTask SR-MMP\n",
      "\tTask SR-p53\n",
      "Dataset for task NR-AR has shape ((5807, 65), (5807, 1), (5807, 1), (5807,))\n",
      "Dataset for task NR-AR-LBD has shape ((5389, 65), (5389, 1), (5389, 1), (5389,))\n",
      "Dataset for task NR-AhR has shape ((5226, 65), (5226, 1), (5226, 1), (5226,))\n",
      "Dataset for task NR-Aromatase has shape ((4651, 65), (4651, 1), (4651, 1), (4651,))\n",
      "Dataset for task NR-ER has shape ((4932, 65), (4932, 1), (4932, 1), (4932,))\n",
      "Dataset for task NR-ER-LBD has shape ((5550, 65), (5550, 1), (5550, 1), (5550,))\n",
      "Dataset for task NR-PPAR-gamma has shape ((5132, 65), (5132, 1), (5132, 1), (5132,))\n",
      "Dataset for task SR-ARE has shape ((4642, 65), (4642, 1), (4642, 1), (4642,))\n",
      "Dataset for task SR-ATAD5 has shape ((5651, 65), (5651, 1), (5651, 1), (5651,))\n",
      "Dataset for task SR-HSE has shape ((5169, 65), (5169, 1), (5169, 1), (5169,))\n",
      "Dataset for task SR-MMP has shape ((4646, 65), (4646, 1), (4646, 1), (4646,))\n",
      "Dataset for task SR-p53 has shape ((5415, 65), (5415, 1), (5415, 1), (5415,))\n",
      "Fitting model for task NR-AR\n",
      "Fitting model for task NR-AR-LBD\n",
      "Fitting model for task NR-AhR\n",
      "Fitting model for task NR-Aromatase\n",
      "Fitting model for task NR-ER\n",
      "Fitting model for task NR-ER-LBD\n",
      "Fitting model for task NR-PPAR-gamma\n",
      "Fitting model for task SR-ARE\n",
      "Fitting model for task SR-ATAD5\n",
      "Fitting model for task SR-HSE\n",
      "Fitting model for task SR-MMP\n",
      "Fitting model for task SR-p53\n",
      "Evaluating model\n",
      "computed_metrics: [1.0, 1.0, 0.9999994572126132, 1.0, 1.0, 1.0, 1.0, 0.9999998260758254, 0.9999850806189101, 1.0, 1.0, 1.0]\n",
      "computed_metrics: [0.8375510204081633, 0.8500386996904024, 0.8527678662452849, 0.8283950617283952, 0.7076748999052243, 0.7561320421290734, 0.8100701633310329, 0.7640576891913791, 0.8322172619047619, 0.7140273471659114, 0.8643928685422462, 0.8312665606783254]\n",
      "computed_metrics: [0.8715316315205328, 0.9346131846131847, 0.8641557128412538, 0.8818011257035647, 0.7439521263050675, 0.8806739203374395, 0.6277268093781856, 0.7518942307692308, 0.8062361572535991, 0.6894346036858113, 0.8662532395409108, 0.8339142963376093]\n",
      "Train scores\n",
      "{'mean-roc_auc_score': 0.9999986969922791}\n",
      "Validation scores\n",
      "{'mean-roc_auc_score': 0.8040492900766832}\n",
      "Test scores\n",
      "{'mean-roc_auc_score': 0.8126822531905323}\n",
      "About to initialize singletask to multitask model\n",
      "Initializing directory for task NR-AR\n",
      "Initializing directory for task NR-AR-LBD\n",
      "Initializing directory for task NR-AhR\n",
      "Initializing directory for task NR-Aromatase\n",
      "Initializing directory for task NR-ER\n",
      "Initializing directory for task NR-ER-LBD\n",
      "Initializing directory for task NR-PPAR-gamma\n",
      "Initializing directory for task SR-ARE\n",
      "Initializing directory for task SR-ATAD5\n",
      "Initializing directory for task SR-HSE\n",
      "Initializing directory for task SR-MMP\n",
      "Initializing directory for task SR-p53\n",
      "About to fit model\n",
      "About to create task-specific datasets\n",
      "Splitting multitask dataset into singletask datasets\n",
      "TIMING: dataset construction took 0.005 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.004 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.003 s\n",
      "Loading dataset from disk.\n",
      "Processing shard 0\n",
      "\tTask NR-AR\n",
      "\tTask NR-AR-LBD\n",
      "\tTask NR-AhR\n",
      "\tTask NR-Aromatase\n",
      "\tTask NR-ER\n",
      "\tTask NR-ER-LBD\n",
      "\tTask NR-PPAR-gamma\n",
      "\tTask SR-ARE\n",
      "\tTask SR-ATAD5\n",
      "\tTask SR-HSE\n",
      "\tTask SR-MMP\n",
      "\tTask SR-p53\n",
      "Dataset for task NR-AR has shape ((5809, 65), (5809, 1), (5809, 1), (5809,))\n",
      "Dataset for task NR-AR-LBD has shape ((5412, 65), (5412, 1), (5412, 1), (5412,))\n",
      "Dataset for task NR-AhR has shape ((5224, 65), (5224, 1), (5224, 1), (5224,))\n",
      "Dataset for task NR-Aromatase has shape ((4659, 65), (4659, 1), (4659, 1), (4659,))\n",
      "Dataset for task NR-ER has shape ((4962, 65), (4962, 1), (4962, 1), (4962,))\n",
      "Dataset for task NR-ER-LBD has shape ((5565, 65), (5565, 1), (5565, 1), (5565,))\n",
      "Dataset for task NR-PPAR-gamma has shape ((5169, 65), (5169, 1), (5169, 1), (5169,))\n",
      "Dataset for task SR-ARE has shape ((4665, 65), (4665, 1), (4665, 1), (4665,))\n",
      "Dataset for task SR-ATAD5 has shape ((5655, 65), (5655, 1), (5655, 1), (5655,))\n",
      "Dataset for task SR-HSE has shape ((5166, 65), (5166, 1), (5166, 1), (5166,))\n",
      "Dataset for task SR-MMP has shape ((4638, 65), (4638, 1), (4638, 1), (4638,))\n",
      "Dataset for task SR-p53 has shape ((5420, 65), (5420, 1), (5420, 1), (5420,))\n",
      "Fitting model for task NR-AR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model for task NR-AR-LBD\n",
      "Fitting model for task NR-AhR\n",
      "Fitting model for task NR-Aromatase\n",
      "Fitting model for task NR-ER\n",
      "Fitting model for task NR-ER-LBD\n",
      "Fitting model for task NR-PPAR-gamma\n",
      "Fitting model for task SR-ARE\n",
      "Fitting model for task SR-ATAD5\n",
      "Fitting model for task SR-HSE\n",
      "Fitting model for task SR-MMP\n",
      "Fitting model for task SR-p53\n",
      "Evaluating model\n",
      "computed_metrics: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "computed_metrics: [0.7871944182142483, 0.7680155210643015, 0.8026440231917431, 0.7294133771929825, 0.6897588010303646, 0.7093112735667564, 0.7843667196608373, 0.7753088924963925, 0.8105515587529976, 0.7117117117117118, 0.8253319713993872, 0.8316956412194507]\n",
      "computed_metrics: [0.8462487153134635, 0.8819307627357162, 0.8704520089285714, 0.843953899628026, 0.7556179775280899, 0.8472399254828906, 0.80789313904068, 0.7860526315789473, 0.8639725658956428, 0.682402881399537, 0.8524919769554963, 0.8179147241647241]\n",
      "Train scores\n",
      "{'mean-roc_auc_score': 1.0}\n",
      "Validation scores\n",
      "{'mean-roc_auc_score': 0.7687753257917644}\n",
      "Test scores\n",
      "{'mean-roc_auc_score': 0.8213476007209821}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tnrange(5):\n",
    "    tox21_datasets = tox21_datasets_lst[i]\n",
    "    train_dataset, valid_dataset, test_dataset = tox21_datasets\n",
    "    n_features = train_dataset.X.shape[1]\n",
    "\n",
    "    # Fit models\n",
    "    metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n",
    "    model = dc.models.SingletaskToMultitask(tox21_tasks_lst[i], model_builder)\n",
    "\n",
    "    # Fit trained model\n",
    "    print(\"About to fit model\")\n",
    "    model.fit(train_dataset)\n",
    "    model.save()\n",
    "    \n",
    "    print(\"Evaluating model\")\n",
    "    train_scores = model.evaluate(train_dataset, [metric], transformers_lst[i])\n",
    "    valid_scores = model.evaluate(valid_dataset, [metric], transformers_lst[i])\n",
    "    test_scores = model.evaluate(test_dataset, [metric], transformers_lst[i])\n",
    "\n",
    "    print(\"Train scores\")\n",
    "    print(train_scores)\n",
    "    train_scores_lst.append(train_scores['mean-roc_auc_score'])\n",
    "\n",
    "    print(\"Validation scores\")\n",
    "    print(valid_scores)\n",
    "    valid_scores_lst.append(valid_scores['mean-roc_auc_score'])\n",
    "    \n",
    "    print(\"Test scores\")\n",
    "    print(test_scores)\n",
    "    test_scores_lst.append(test_scores['mean-roc_auc_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MolEnv3",
   "language": "python",
   "name": "molenv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "166px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
